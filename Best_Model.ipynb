{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93d81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c9114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the dataframe from the CSV file\n",
    "df = pd.read_csv('Strat_Temp_AOD_Flux.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0ae9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract lat, lon, and dates\n",
    "lon_vals = df['lon'].unique()\n",
    "lat_vals = df['lat'].unique()\n",
    "dates = df['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7db688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 16x48x120 tensor for Temperature data\n",
    "data_tot = torch.empty(size=(16,48,120))\n",
    "for i in range(len(lat_vals)):\n",
    "    for j in range(len(lon_vals)):\n",
    "        temp = df[(df['lat'] == lat_vals[i]) & (df['lon'] == lon_vals[j])]\n",
    "        data_tot[i,j,:] = torch.from_numpy(np.array(temp['T'])).float()\n",
    "#data_tot contains all the temperatures from all spatial points (16x48) with 120 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5eba68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates sliding window and normalizes X-values (inputs to the CNN)\n",
    "def sliding_window(dates, data, seq_len, out_len): \n",
    "    x, y, start_dates = [], [], []\n",
    "    \n",
    "    for j in range(len(data[0,0]) - seq_len - out_len): #create sliding windows\n",
    "        _x = data[:,:,j:(j+seq_len)]\n",
    "        _y = data[:,:, (j+seq_len):(j+seq_len+out_len)]\n",
    "        x_date = dates[j]\n",
    "        y_date = dates[j+seq_len]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "        start_dates.append((x_date, y_date))\n",
    "    #Normalize\n",
    "    x = np.array(x)\n",
    "    xmax = x.max()\n",
    "    xmin = x.min()\n",
    "    x_norm = (x - xmin) / (xmax - xmin)\n",
    "    return start_dates, x_norm, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef063b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set A contains first 38 time steps\n",
    "#Training set B contains first 49 time steps\n",
    "sequence_len = 24\n",
    "output_len = 6\n",
    "x_start_dates, x_tot, y_tot =  sliding_window(dates, np.array(data_tot), sequence_len, output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6067ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab training set A x-temperatures\n",
    "x_train_A = torch.from_numpy(x_tot[:31,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943edfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab training set A y-temperatures\n",
    "y_train_A = torch.from_numpy(y_tot[:31,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf7379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab training set B x-temperatures\n",
    "x_train_B = torch.from_numpy(x_tot[:42,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3e91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab training set B y-temperatures\n",
    "y_train_B = torch.from_numpy(y_tot[:42,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63892129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab test set A x-temperatures\n",
    "x_test_A = torch.from_numpy(x_tot[31:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58573c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab test set A y-temperatures\n",
    "y_test_A = torch.from_numpy(y_tot[31:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b3d29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab test set B x-temperatures\n",
    "x_test_B = torch.from_numpy(x_tot[42:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26904f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab test set B y-temperatures\n",
    "y_test_B = torch.from_numpy(y_tot[42:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db63bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We must convert the dimensions to [1, number of time steps, 16,48] to input into the CNN\n",
    "x_train_A = torch.permute(x_train_A, (0,3,1,2))\n",
    "y_train_A = torch.permute(y_train_A, (0,3,1,2))\n",
    "\n",
    "x_train_B = torch.permute(x_train_B, (0,3,1,2))\n",
    "y_train_B = torch.permute(y_train_B, (0,3,1,2))\n",
    "\n",
    "x_test_A = torch.permute(x_test_A, (0,3,1,2))\n",
    "y_test_A = torch.permute(y_test_A, (0,3,1,2))\n",
    "\n",
    "x_test_B = torch.permute(x_test_B, (0,3,1,2))\n",
    "y_test_B = torch.permute(y_test_B, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d6d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function converts all sets to list of 16x48xtime tensors!!\n",
    "def list_of_tensors(tensor):\n",
    "    list_tensor = []\n",
    "    for i in range(len(tensor)):\n",
    "        list_tensor.append(tensor[i])\n",
    "    return list_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87bd1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the input to the CNN we must get a list of tensors size (1,time_steps,16,48)\n",
    "x_train_A = list_of_tensors(x_train_A)\n",
    "y_train_A = list_of_tensors(y_train_A)\n",
    "\n",
    "x_train_B = list_of_tensors(x_train_B)\n",
    "y_train_B = list_of_tensors(y_train_B)\n",
    "\n",
    "x_test_A = list_of_tensors(x_test_A)\n",
    "y_test_A = list_of_tensors(y_test_A)\n",
    "\n",
    "x_test_B = list_of_tensors(x_test_B)\n",
    "y_test_B = list_of_tensors(y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd07a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #24 in-channels for context, 6 out-channels for horizon, kernel size 3x3\n",
    "        self.conv1 = nn.Conv2d(24, 6, 3, padding='same') \n",
    "        #self.conv2 = nn.Conv2d(24, 6, 3, padding='same')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "703e5d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The latitude weights are the cosines of the latitude values\n",
    "\n",
    "def weighted_RMSE(output, target):\n",
    "    lat_weights = [ 0.98611103,  0.85521133,  0.72431164,  0.59341195,  0.46251225,\n",
    "        0.33161256,  0.20071286,  0.06981317, -0.06108652, -0.19198622,\n",
    "       -0.32288591, -0.45378561, -0.5846853 , -0.71558499, -0.84648469,\n",
    "       -0.97738438] #Latitudes converted to radians\n",
    "    loss = torch.mean(torch.mul((output - target)**2, torch.tensor(np.cos(lat_weights))[:,None]))\n",
    "    return torch.sqrt(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c30ab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 191.31708 test loss:  190.10532 \n",
      "Epoch: 500, loss: 46.32251 test loss:  44.68679 \n",
      "Epoch: 1000, loss: 41.69821 test loss:  41.33567 \n",
      "Epoch: 1500, loss: 37.69879 test loss:  38.20395 \n",
      "Epoch: 2000, loss: 33.94496 test loss:  35.00249 \n",
      "Epoch: 2500, loss: 30.30500 test loss:  31.68357 \n",
      "Epoch: 3000, loss: 26.73129 test loss:  28.26242 \n",
      "Epoch: 3500, loss: 23.20609 test loss:  24.76437 \n",
      "Epoch: 4000, loss: 19.72366 test loss:  21.21294 \n",
      "Epoch: 4500, loss: 16.28521 test loss:  17.62933 \n",
      "Epoch: 5000, loss: 12.89880 test loss:  14.03519 \n",
      "Epoch: 5500, loss: 9.58604 test loss:  10.46069 \n",
      "Epoch: 6000, loss: 6.40503 test loss:  6.96743 \n",
      "Epoch: 6500, loss: 3.56732 test loss:  3.76964 \n",
      "Epoch: 7000, loss: 1.94489 test loss:  1.89876 \n",
      "Epoch: 7500, loss: 1.68755 test loss:  1.71597 \n",
      "Epoch: 7999, loss: 1.63285 test loss:  1.71460 \n"
     ]
    }
   ],
   "source": [
    "#Training loop for training set A Temperature only\n",
    "n_epochs = 8000 #Can tune this parameter\n",
    "learning_rate = 1e-3 #Can tune this parameter\n",
    "\n",
    "cnn = CNN()\n",
    "#criterion = weighted_RMSE()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = learning_rate)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    avg_loss = 0\n",
    "    for j in range(len(x_train_A)):\n",
    "        cnn.train()\n",
    "        outputs = cnn(x_train_A[j])\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        loss = weighted_RMSE(outputs, y_train_A[j])\n",
    "        avg_loss += loss\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "    avg_loss = avg_loss/len(x_train_A)\n",
    "    avg_loss_test = 0\n",
    "    for k in range(len(x_test_A)):\n",
    "        cnn.eval()\n",
    "        valid = cnn(x_test_A[k])\n",
    "        test_loss = weighted_RMSE(valid, y_test_A[k])\n",
    "        avg_loss_test += test_loss\n",
    "    avg_loss_test = avg_loss_test/len(x_test_A)\n",
    "    if i %500 == 0 or i == n_epochs-1:\n",
    "        print(\"Epoch: %d, loss: %1.5f test loss:  %1.5f \" %(i, avg_loss , avg_loss_test))\n",
    "        \n",
    "#Use torch.save() to save your model so you don't have to train another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d650bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 190.96670 test loss:  189.32624 \n",
      "Epoch: 500, loss: 43.64102 test loss:  44.00983 \n",
      "Epoch: 1000, loss: 38.04231 test loss:  39.98075 \n",
      "Epoch: 1500, loss: 33.04848 test loss:  35.83627 \n",
      "Epoch: 2000, loss: 28.27120 test loss:  31.40964 \n",
      "Epoch: 2500, loss: 23.61926 test loss:  26.77165 \n",
      "Epoch: 3000, loss: 19.07447 test loss:  22.00208 \n",
      "Epoch: 3500, loss: 14.64767 test loss:  17.17141 \n",
      "Epoch: 4000, loss: 10.38297 test loss:  12.36132 \n",
      "Epoch: 4500, loss: 6.40702 test loss:  7.72254 \n",
      "Epoch: 5000, loss: 3.16916 test loss:  3.72569 \n",
      "Epoch: 5500, loss: 1.84230 test loss:  1.82869 \n",
      "Epoch: 6000, loss: 1.68984 test loss:  1.63855 \n",
      "Epoch: 6500, loss: 1.65377 test loss:  1.63728 \n",
      "Epoch: 7000, loss: 1.63191 test loss:  1.64318 \n",
      "Epoch: 7500, loss: 1.61642 test loss:  1.65060 \n",
      "Epoch: 7999, loss: 1.60510 test loss:  1.65883 \n"
     ]
    }
   ],
   "source": [
    "#Training loop for training set B Temperature only\n",
    "n_epochs = 8000 #Can tune this parameter\n",
    "learning_rate = 1e-3 #Can tune this parameter\n",
    "\n",
    "cnn_B = CNN()\n",
    "#criterion = RMSELoss()\n",
    "optimizer = optim.Adam(cnn_B.parameters(), lr = learning_rate)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    avg_loss = 0\n",
    "    for j in range(len(x_train_B)):\n",
    "        cnn_B.train()\n",
    "        outputs = cnn_B(x_train_B[j])\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        loss = weighted_RMSE(outputs, y_train_B[j])\n",
    "        avg_loss += loss\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "    avg_loss = avg_loss/len(x_train_B)\n",
    "    avg_loss_test = 0\n",
    "    for k in range(len(x_test_B)):\n",
    "        cnn_B.eval()\n",
    "        valid = cnn_B(x_test_B[k])\n",
    "        test_loss = weighted_RMSE(valid, y_test_B[k])\n",
    "        avg_loss_test += test_loss\n",
    "    avg_loss_test = avg_loss_test/len(x_test_B)\n",
    "    if i %500 == 0 or i == n_epochs-1:\n",
    "        print(\"Epoch: %d, loss: %1.5f test loss:  %1.5f \" %(i, avg_loss , avg_loss_test))\n",
    "        \n",
    "#Use torch.save() to save your model so you don't have to train another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c2348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
